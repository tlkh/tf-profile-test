{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "laUXS-24UvPM"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "zNbGLsDSUe3W",
    "outputId": "4e551e00-c5a8-4d41-f6c2-7269f7941a68"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import tensorflow\n",
    "print(\"TensorFlow version:\", tensorflow.__version__)\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ObRNSvQMUxbI"
   },
   "source": [
    "# Pets Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TiQp7Apm516"
   },
   "outputs": [],
   "source": [
    "# enable XLA\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# enable AMP\n",
    "#tf.keras.mixed_precision.experimental.set_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCK57jlvNpOO"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "def create_model(img_size=(224,224), num_class=2, train_base=True):\n",
    "    # accept float16 image inputs\n",
    "    input_layer = layers.Input(shape=(img_size[0],img_size[1],3), dtype=tf.float16)\n",
    "    base = ResNet50(input_tensor=input_layer,\n",
    "                    include_top=False,\n",
    "                    weights=\"imagenet\")\n",
    "    base.trainable = train_base\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    # softmax only accepts float32 - need to manually cast (likely a bug)\n",
    "    preds = layers.Dense(num_class, activation=\"softmax\", dtype=tf.float32)(x)\n",
    "    return tf.keras.models.Model(inputs=input_layer, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICDyhaNCdNsm"
   },
   "outputs": [],
   "source": [
    "(train_dataset, test_dataset), info = tfds.load(name=\"oxford_iiit_pet:3.*.*\",\n",
    "                                                split=[\"train\", \"test\"],\n",
    "                                                shuffle_files=True,\n",
    "                                                as_supervised=True,\n",
    "                                                with_info=True)\n",
    "\n",
    "num_class = info.features[\"label\"].num_classes\n",
    "num_train = info.splits[\"train\"].num_examples\n",
    "num_test  = info.splits[\"test\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdWvubj3g2aO"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "@tf.function\n",
    "def format_train_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    # perform image augmentation with tf.image\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "    # return images as float16\n",
    "    image = tf.cast(image, tf.float16)\n",
    "    return image, tf.one_hot(label, num_class)\n",
    "\n",
    "@tf.function\n",
    "def format_eval_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    # return images as float16\n",
    "    image = tf.cast(image, tf.float16)\n",
    "    return image, tf.one_hot(label, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbsEAoP8XKib"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 80\n",
    "N_THREADS = multiprocessing.cpu_count()\n",
    "PREFETCH_COUNT = 8\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1024)\n",
    "train_dataset = train_dataset.repeat(-1)\n",
    "train_dataset = train_dataset.map(format_train_example,\n",
    "                                  num_parallel_calls=N_THREADS)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(PREFETCH_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-OAQB-0jb-r"
   },
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.map(format_eval_example,\n",
    "                                num_parallel_calls=N_THREADS)\n",
    "test_dataset = test_dataset.repeat(-1)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAwj90pGOIAy"
   },
   "outputs": [],
   "source": [
    "model = create_model(IMG_SIZE, num_class, train_base=True)\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vRtm2rORBHf"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = num_train//BATCH_SIZE\n",
    "steps_test = num_test//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "7T8VVrn4Q12B",
    "outputId": "d5b7a7c7-0970-45ef-898e-283abfe787a6"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n",
    "          epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager import profiler\n",
    "from tensorflow.core.protobuf import trace_events_pb2\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeP0nP1Em52O"
   },
   "outputs": [],
   "source": [
    "profiler.start()\n",
    "model.fit(train_dataset, steps_per_epoch=3, epochs=1, verbose=2)\n",
    "model_profile = profiler.stop()\n",
    "\n",
    "profile_pb = trace_events_pb2.Trace()\n",
    "profile_pb.ParseFromString(model_profile)\n",
    "\n",
    "profile_dict = MessageToDict(profile_pb)\n",
    "\n",
    "timing_dict = {\n",
    "    \"hmma\": 0,\n",
    "    \"hmma_events\": [],\n",
    "    \"other_fp16\": 0,\n",
    "    \"other_fp16_events\": [],\n",
    "    \"sgemm\": 0,\n",
    "    \"sgemm_events\": [],\n",
    "    \"copy\": 0,\n",
    "    \"copy_events\": [],\n",
    "    \"xla\": 0,\n",
    "    \"xla_events\": [],\n",
    "    \"others\": 0,\n",
    "    \"others_events\": [],\n",
    "    \"total\": 0\n",
    "}\n",
    "\n",
    "for event in profile_dict[\"traceEvents\"]:\n",
    "    try:\n",
    "        device_id = int(event[\"deviceId\"])\n",
    "        event_timestamp = int(event[\"timestampPs\"])\n",
    "        if device_id == 1:\n",
    "            event_name = event[\"name\"].lower()\n",
    "            event_time = int(event[\"durationPs\"])\n",
    "            # tensor core (HMMA) events\n",
    "            if \"hmma\" in event_name or \"884\" in event_name and event_name != \"fusion_884\":\n",
    "                timing_dict[\"hmma\"] += event_time\n",
    "                if event_name not in timing_dict[\"hmma_events\"]:\n",
    "                    timing_dict[\"hmma_events\"].append(event_name)\n",
    "            # FP16 events\n",
    "            elif \"fp16\" in event_name:\n",
    "                timing_dict[\"other_fp16\"] += event_time\n",
    "                if event_name not in timing_dict[\"other_fp16_events\"]:\n",
    "                    timing_dict[\"other_fp16_events\"].append(event_name)\n",
    "            # FP32 GEMM events\n",
    "            elif \"sgemm\" in event_name:\n",
    "                timing_dict[\"sgemm\"] += event_time\n",
    "                if event_name not in timing_dict[\"sgemm_events\"]:\n",
    "                    timing_dict[\"sgemm_events\"].append(event_name)\n",
    "            # Transfer events\n",
    "            elif \"copy\" in event_name or \"cpy\" in event_name:\n",
    "                timing_dict[\"copy\"] += event_time\n",
    "                if event_name not in timing_dict[\"copy_events\"]:\n",
    "                    timing_dict[\"copy_events\"].append(event_name)\n",
    "            # XLA fusion ops\n",
    "            elif \"fusion\" in event_name:\n",
    "                timing_dict[\"xla\"] += event_time\n",
    "                if event_name not in timing_dict[\"xla_events\"]:\n",
    "                    timing_dict[\"xla_events\"].append(event_name)\n",
    "            # all other events\n",
    "            else:\n",
    "                timing_dict[\"others\"] += event_time\n",
    "                if event_name not in timing_dict[\"others_events\"]:\n",
    "                    timing_dict[\"others_events\"].append(event_name)\n",
    "            timing_dict[\"total\"] += event_time\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "print(\"= type (num_type) % time =\")\n",
    "# consider compute time only\n",
    "total = timing_dict[\"total\"] - timing_dict[\"copy\"] - timing_dict[\"others\"]\n",
    "print(\"- hmma (\", len(timing_dict[\"hmma_events\"]), \")\\t\", round(timing_dict[\"hmma\"]/total*100, 1))\n",
    "print(\"- fp16 (\", len(timing_dict[\"other_fp16_events\"]), \")\\t\", round(timing_dict[\"other_fp16\"]/total*100, 1))\n",
    "print(\"- sgemm (\", len(timing_dict[\"sgemm_events\"]), \")\\t\", round(timing_dict[\"sgemm\"]/total*100, 1))\n",
    "#print(\"- copy (\", len(timing_dict[\"copy_events\"]), \")\\t\", round(timing_dict[\"copy\"]/total*100, 1))\n",
    "print(\"- xla (\", len(timing_dict[\"xla_events\"]), \")\\t\", round(timing_dict[\"xla\"]/total*100, 1))\n",
    "#print(\"- others (\", len(timing_dict[\"others_events\"]), \")\\t\", round(timing_dict[\"others\"]/total*100, 1))\n",
    "print(\"Total time:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "laUXS-24UvPM"
   ],
   "name": "tf_pet_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
