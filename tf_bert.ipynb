{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWGze6qCm6Pu"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "got-iOfem6Py"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpOFAo4Km6P2"
   },
   "source": [
    "# Sequence Classification with BERT in TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sr25k7aNm6P2"
   },
   "outputs": [],
   "source": [
    "# enable XLA\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# enable AMP via tf.config\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1Lz61HGm6P4"
   },
   "source": [
    "## Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjMRDhSxm6P5"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "saAtsXk-m6P7"
   },
   "source": [
    "## Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvmttt3mm6P7"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FyaLd5x7m6P8",
    "outputId": "a349e397-a488-405c-d6bf-53562f87f377"
   },
   "outputs": [],
   "source": [
    "data, info = tensorflow_datasets.load(\"glue/mrpc\", with_info=True)\n",
    "\n",
    "train_examples = info.splits[\"train\"].num_examples\n",
    "valid_examples = info.splits[\"validation\"].num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCMkgYi5m6P-"
   },
   "source": [
    "## Build Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-tl2kZEm6P-"
   },
   "outputs": [],
   "source": [
    "from transformers import glue_convert_examples_to_features\n",
    "\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "# Prepare dataset for GLUE as a tf.data.Dataset instance\n",
    "train_dataset = glue_convert_examples_to_features(data[\"train\"], tokenizer, 128, \"mrpc\")\n",
    "train_dataset = train_dataset.repeat(-1).shuffle(512).batch(BATCH_SIZE).prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqgFrbdbm6QA"
   },
   "source": [
    "## Build BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yh2myknm6QB"
   },
   "source": [
    "### Load Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpEvDnxum6QB"
   },
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZvnCMjUzm6QD"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "# do loss scaling for optimizer\n",
    "opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, \"dynamic\")\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss,\n",
    "              metrics=[acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TU_GlzZom6QF"
   },
   "source": [
    "## Train BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXXUn0sem6QH",
    "outputId": "08bcdf53-a763-4ec1-bb69-0646efc5414a"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=2, steps_per_epoch=train_examples//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager import profiler\n",
    "from tensorflow.core.protobuf import trace_events_pb2\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.start()\n",
    "model.fit(train_dataset, steps_per_epoch=3, epochs=1, verbose=2)\n",
    "model_profile = profiler.stop()\n",
    "\n",
    "profile_pb = trace_events_pb2.Trace()\n",
    "profile_pb.ParseFromString(model_profile)\n",
    "\n",
    "profile_dict = MessageToDict(profile_pb)\n",
    "\n",
    "timing_dict = {\n",
    "    \"hmma\": 0,\n",
    "    \"hmma_events\": [],\n",
    "    \"other_fp16\": 0,\n",
    "    \"other_fp16_events\": [],\n",
    "    \"sgemm\": 0,\n",
    "    \"sgemm_events\": [],\n",
    "    \"copy\": 0,\n",
    "    \"copy_events\": [],\n",
    "    \"xla\": 0,\n",
    "    \"xla_events\": [],\n",
    "    \"others\": 0,\n",
    "    \"others_events\": [],\n",
    "    \"total\": 0\n",
    "}\n",
    "\n",
    "for event in profile_dict[\"traceEvents\"]:\n",
    "    try:\n",
    "        device_id = int(event[\"deviceId\"])\n",
    "        event_timestamp = int(event[\"timestampPs\"])\n",
    "        if device_id == 1:\n",
    "            event_name = event[\"name\"].lower()\n",
    "            event_time = int(event[\"durationPs\"])\n",
    "            # tensor core (HMMA) events\n",
    "            if \"hmma\" in event_name or \"884\" in event_name and event_name != \"fusion_884\":\n",
    "                timing_dict[\"hmma\"] += event_time\n",
    "                if event_name not in timing_dict[\"hmma_events\"]:\n",
    "                    timing_dict[\"hmma_events\"].append(event_name)\n",
    "            # FP16 events\n",
    "            elif \"fp16\" in event_name:\n",
    "                timing_dict[\"other_fp16\"] += event_time\n",
    "                if event_name not in timing_dict[\"other_fp16_events\"]:\n",
    "                    timing_dict[\"other_fp16_events\"].append(event_name)\n",
    "            # FP32 GEMM events\n",
    "            elif \"sgemm\" in event_name:\n",
    "                timing_dict[\"sgemm\"] += event_time\n",
    "                if event_name not in timing_dict[\"sgemm_events\"]:\n",
    "                    timing_dict[\"sgemm_events\"].append(event_name)\n",
    "            # Transfer events\n",
    "            elif \"copy\" in event_name or \"cpy\" in event_name:\n",
    "                timing_dict[\"copy\"] += event_time\n",
    "                if event_name not in timing_dict[\"copy_events\"]:\n",
    "                    timing_dict[\"copy_events\"].append(event_name)\n",
    "            # XLA fusion ops\n",
    "            elif \"fusion\" in event_name:\n",
    "                timing_dict[\"xla\"] += event_time\n",
    "                if event_name not in timing_dict[\"xla_events\"]:\n",
    "                    timing_dict[\"xla_events\"].append(event_name)\n",
    "            # all other events\n",
    "            else:\n",
    "                timing_dict[\"others\"] += event_time\n",
    "                if event_name not in timing_dict[\"others_events\"]:\n",
    "                    timing_dict[\"others_events\"].append(event_name)\n",
    "            timing_dict[\"total\"] += event_time\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "print(\"= type (num_type) % time =\")\n",
    "# consider compute time only\n",
    "total = timing_dict[\"total\"] - timing_dict[\"copy\"] - timing_dict[\"others\"]\n",
    "print(\"- hmma (\", len(timing_dict[\"hmma_events\"]), \")\\t\", round(timing_dict[\"hmma\"]/total*100, 1))\n",
    "print(\"- fp16 (\", len(timing_dict[\"other_fp16_events\"]), \")\\t\", round(timing_dict[\"other_fp16\"]/total*100, 1))\n",
    "print(\"- sgemm (\", len(timing_dict[\"sgemm_events\"]), \")\\t\", round(timing_dict[\"sgemm\"]/total*100, 1))\n",
    "#print(\"- copy (\", len(timing_dict[\"copy_events\"]), \")\\t\", round(timing_dict[\"copy\"]/total*100, 1))\n",
    "print(\"- xla (\", len(timing_dict[\"xla_events\"]), \")\\t\", round(timing_dict[\"xla\"]/total*100, 1))\n",
    "#print(\"- others (\", len(timing_dict[\"others_events\"]), \")\\t\", round(timing_dict[\"others\"]/total*100, 1))\n",
    "print(\"Total time:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NWGze6qCm6Pu"
   ],
   "name": "tf_transformer_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
